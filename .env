# Pascal AI Assistant Environment Variables - FIXED API Key Formats
# Copy this file to .env and add your actual API keys

# ‚ö° LIGHTNING PERFORMANCE SETTINGS
PERFORMANCE_MODE=balanced              # speed/balanced/quality
STREAMING_ENABLED=true                 # Enable streaming for instant feedback
KEEP_ALIVE_ENABLED=true               # Keep models loaded in memory
TARGET_RESPONSE_TIME=3.0              # Target max response time in seconds
MAX_RESPONSE_TOKENS=200               # Limit tokens for faster responses

# ü§ñ ONLINE API KEYS (Priority Order: Groq -> Gemini -> OpenAI)

# Groq API (PRIMARY - Very Fast) - Get from https://console.groq.com/
# FIXED: New Groq API keys start with gsk_ (underscore, not dash)
# Format: gsk_... (starts with gsk_)
GROQ_API_KEY=gsk_your_groq_api_key_here

# Google Gemini API (SECONDARY - Free & Good Quality) - Get from https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
# Alternative: You can also use GOOGLE_API_KEY if you prefer
# GOOGLE_API_KEY=your_google_api_key_here

# OpenAI API (FALLBACK - Reliable but Paid) - Get from https://platform.openai.com/api-keys
# Format: sk-... (starts with sk-)
OPENAI_API_KEY=sk-your_openai_api_key_here

# üîß OLLAMA SETTINGS
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=30
OLLAMA_KEEP_ALIVE=30m              # Keep models loaded for 30 minutes

# üíæ MEMORY SETTINGS
SHORT_TERM_MEMORY_LIMIT=5
LONG_TERM_MEMORY_ENABLED=true
MEMORY_SAVE_INTERVAL=300

# üêõ DEBUG SETTINGS
DEBUG=false                       # Set to true for detailed debugging
LOG_LEVEL=INFO
PERF_LOG=false                    # Enable performance logging

# ‚öôÔ∏è ADVANCED SETTINGS
MAX_CONCURRENT_REQUESTS=2         # Limited for Pi 5 stability
CACHE_EXPIRY=3600
LLM_THREADS=4                     # Use all Pi 5 cores
LLM_CONTEXT=2048                  # Context window size

# üéØ PREFERRED MODELS (in priority order)
# These are automatically downloaded and configured
# 1. nemotron-mini:4b-instruct-q4_K_M (PRIMARY - fastest)
# 2. qwen2.5:3b (FALLBACK 1 - updated Qwen)
# 3. phi3:mini (FALLBACK 2 - reliable)
# 4. llama3.2:3b (FALLBACK 3 - current Llama)
# 5. gemma2:2b (FALLBACK 4 - lightweight)

# üìù API KEY SETUP INSTRUCTIONS:

# Groq (Recommended for speed and current info):
#   1. Go to https://console.groq.com/
#   2. Sign up for free account
#   3. Generate API key (starts with gsk_)
#   4. Replace gsk_your_groq_api_key_here with your actual key
#   IMPORTANT: New Groq keys use gsk_ (underscore), not gsk- (dash)
#
# Gemini (Free option):
#   1. Go to https://aistudio.google.com/app/apikey
#   2. Sign in with Google account
#   3. Create API key
#   4. Replace your_gemini_api_key_here with your actual key
#
# OpenAI (Paid but reliable):
#   1. Go to https://platform.openai.com/api-keys
#   2. Sign up and add payment method
#   3. Create API key (starts with sk-)
#   4. Replace sk_your_openai_api_key_here with your actual key

# üí° RECOMMENDATION:
# For best performance, configure GROQ_API_KEY first.
# Groq provides lightning-fast responses and is free for most usage.
# It's especially important for queries about current events, dates, and recent information.
# Add GEMINI_API_KEY as a free backup option.
# Only add OPENAI_API_KEY if you need maximum reliability and don't mind paying.

# üîç TROUBLESHOOTING:
# If Pascal can't answer questions about current events or today's date:
# 1. Make sure GROQ_API_KEY is set correctly (starts with gsk_)
# 2. Check that you're using GROQ_API_KEY not GROK_API_KEY
# 3. Verify your API key format: new keys use gsk_ not gsk-
# 4. Test with: python test_groq_fix.py
# 5. Enable debug mode: DEBUG=true

# üîÑ MIGRATION NOTE:
# If you previously used GROK_API_KEY, rename it to GROQ_API_KEY
# If your key starts with gsk-, it should work but consider updating to gsk_
# Pascal will automatically detect both for backward compatibility
