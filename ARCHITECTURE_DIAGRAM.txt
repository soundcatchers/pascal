═══════════════════════════════════════════════════════════════════════════════
                    PASCAL AI ASSISTANT - ARCHITECTURE DIAGRAM
═══════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│                              USER INTERACTION                                │
└─────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     │ User Input
                                     ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                           MAIN.PY (Entry Point)                              │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │  Pascal Class                                                         │  │
│  │  • Initialize components                                              │  │
│  │  • Process user commands (help, status, clear, quit)                 │  │
│  │  • Handle chat loop                                                   │  │
│  │  • Display status and statistics                                     │  │
│  │  • Graceful shutdown                                                  │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────────┘
         │                    │                              │
         │ init               │ init                         │ init
         ↓                    ↓                              ↓
┌──────────────────┐  ┌──────────────────┐  ┌───────────────────────────────┐
│ PersonalityMgr   │  │   MemoryManager  │  │   LightningRouter (Core)      │
│                  │  │                  │  │                               │
│ • Load config    │  │ • Short-term     │  │  ┌─────────────────────────┐ │
│ • System prompt  │  │ • Long-term      │  │  │ Query Analysis          │ │
│ • Speaking style │  │ • Preferences    │  │  │ • EnhancedQueryAnalyzer │ │
│ • Greetings      │  │ • Learned facts  │  │  │ • Intent detection      │ │
│ • Traits         │  │ • Auto-save      │  │  │ • Complexity scoring    │ │
│                  │  │ • Context gen    │  │  │ • Temporal detection    │ │
└──────────────────┘  └──────────────────┘  │  │ • Domain detection      │ │
         │                    │              │  │ • Follow-up detection   │ │
         │ Context            │ Context      │  └─────────────────────────┘ │
         │                    │              │             │                 │
         └────────────────────┴──────────────┼─────────────┘                 │
                                             │                               │
                                             │  ┌─────────────────────────┐ │
                                             │  │ Routing Decision        │ │
                                             │  │ • System availability   │ │
                                             │  │ • Performance history   │ │
                                             │  │ • Confidence scoring    │ │
                                             │  │ • Fallback selection    │ │
                                             │  └─────────────────────────┘ │
                                             └───────────────────────────────┘
                                                      │
                                  ┌───────────────────┴────────────────────┐
                                  │                                        │
                          Route: OFFLINE                           Route: ONLINE
                                  │                                        │
                                  ↓                                        ↓
┌─────────────────────────────────────────────┐  ┌──────────────────────────────────────────────┐
│   OFFLINE LLM (modules/offline_llm.py)      │  │   ONLINE LLM (modules/online_llm.py)         │
│                                             │  │                                              │
│  LightningOfflineLLM                        │  │  OnlineLLM                                   │
│  ┌───────────────────────────────────────┐ │  │  ┌────────────────────────────────────────┐ │
│  │ OLLAMA Integration                    │ │  │  │ GROQ API Integration                   │ │
│  │ • HTTP API client (aiohttp)           │ │  │  │ • API: llama-3.1-8b-instant           │ │
│  │ • Model: nemotron-mini:4b             │ │  │  │ • Streaming responses                  │ │
│  │ • Endpoint: http://localhost:11434    │ │  │  │ • Auth: Bearer token                   │ │
│  │                                       │ │  │  │                                        │ │
│  │ Model Selection (Priority):           │ │  │  │ Search Integration:                    │ │
│  │ 1. nemotron-mini:4b-instruct-q4_K_M   │ │  │  │ ┌────────────────────────────────────┐ │ │
│  │ 2. nemotron-fast                      │ │  │  │ │ Google Custom Search API           │ │ │
│  │ 3. qwen2.5:3b-instruct                │ │  │  │ │ • General search (sports, facts)   │ │ │
│  │ 4. phi3:mini                          │ │  │  │ │ • News search (breaking news)      │ │ │
│  │ 5. gemma2:2b                          │ │  │  │ │ • Query optimization               │ │ │
│  │                                       │ │  │  │ │ • Source citation                  │ │ │
│  │ Performance Profiles:                 │ │  │  │ │ • Fallback search                  │ │ │
│  │ • Speed:    80 tokens, 512 ctx        │ │  │  │ └────────────────────────────────────┘ │ │
│  │   Target: 2-4s                        │ │  │  │              │                          │ │
│  │ • Balanced: 150 tokens, 1024 ctx      │ │  │  │              ↓                          │ │
│  │   Target: 3-6s                        │ │  │  │  ┌────────────────────────────────────┐ │ │
│  │ • Quality:  300 tokens, 2048 ctx      │ │  │  │  │ Search Detection                   │ │ │
│  │   Target: 5-10s                       │ │  │  │  │ • Temporal indicators              │ │ │
│  │                                       │ │  │  │  │ • Sports patterns                  │ │ │
│  │ Features:                             │ │  │  │  │ • News patterns                    │ │ │
│  │ • Keep-alive (30m)                    │ │  │  │  │ • Current info patterns            │ │ │
│  │ • Model health monitoring             │ │  │  │  └────────────────────────────────────┘ │ │
│  │ • Automatic model testing             │ │  │  │              │                          │ │
│  │ • Nonsense detection                  │ │  │  │              ↓                          │ │
│  │ • Connection pooling                  │ │  │  │  ┌────────────────────────────────────┐ │ │
│  │ • Streaming & non-streaming           │ │  │  │  │ Response Enhancement               │ │ │
│  │                                       │ │  │  │  │ • Inject current datetime          │ │ │
│  └───────────────────────────────────────┘ │  │  │  │ • Format search results            │ │ │
│                                             │  │  │  │ • Add source attribution           │ │ │
│  Prompt Building:                           │  │  │  │ • Context integration              │ │ │
│  • Personality context (300 chars)          │  │  │  └────────────────────────────────────┘ │ │
│  • Memory context (300 chars)               │  │  └────────────────────────────────────────┘ │
│  • Ultra-minimal for speed                  │  │                                              │
│  • Skip context for short queries (<8 words)│  │  Prompt Building:                            │
│                                             │  │  • System message with datetime              │
│                                             │  │  • Personality context (200 chars)           │
└─────────────────────────────────────────────┘  │  • Memory context (200 chars)                │
                                                  │  • Search results formatting                 │
                                                  │  • Source citation instructions              │
                                                  └──────────────────────────────────────────────┘
         │                                                        │
         │ Response Stream                                       │ Response Stream
         └────────────────────┬───────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                          RESPONSE PROCESSING                                 │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ • Stream tokens to user                                                │ │
│  │ • Collect complete response                                            │ │
│  │ • Extract metadata (sources, timestamps)                               │ │
│  │ • Track performance (response time, success)                           │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────┘
                              │
                              ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                         MEMORY UPDATE & LEARNING                             │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ MemoryManager.add_interaction()                                        │ │
│  │ • Store user input                                                     │ │
│  │ • Store assistant response                                             │ │
│  │ • Store metadata (sources, search info)                                │ │
│  │ • Extract preferences (likes, dislikes)                                │ │
│  │ • Extract facts (name, job, location)                                  │ │
│  │ • Auto-save if interval elapsed (5 min)                                │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────┘
                              │
                              ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                       PERFORMANCE TRACKING                                   │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ PerformanceTracker.record_request()                                    │ │
│  │ • Record response time                                                 │ │
│  │ • Update success/failure count                                         │ │
│  │ • Calculate health score                                               │ │
│  │ • Track consecutive errors                                             │ │
│  │ • Update average response time                                         │ │
│  │ • Store query type performance                                         │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════
                           CONFIGURATION LAYER
═══════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│                    config/settings.py (Central Config)                       │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ Settings Class                                                         │ │
│  │ • Hardware detection (Pi model, RAM, cores)                            │ │
│  │ • API key validation (Groq, Google)                                    │ │
│  │ • Performance optimization (ultra-speed for Pi 5)                      │ │
│  │ • Ollama configuration (host, timeout, threads)                        │ │
│  │ • Memory limits (short-term, long-term)                                │ │
│  │ • Context windows (64-256 tokens)                                      │ │
│  │ • Response tokens (40-60 tokens)                                       │ │
│  │ • Target response time (1.5s ultra-aggressive)                         │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────┘
         │                    │                          │
         ↓                    ↓                          ↓
    .env file         config/personalities/      data/memory/
    ────────          ────────────────────       ────────────
    GROQ_API_KEY      default.json               default_memory.json
    GOOGLE_SEARCH_API assistant.json             • Short-term history
    GOOGLE_SEARCH_ID  custom.json                • Long-term history
    DEBUG=true        • Personality traits       • User preferences
    PERFORMANCE_MODE  • Speaking style           • Learned facts
                      • System prompts
                      • Conversation phrases


═══════════════════════════════════════════════════════════════════════════════
                         DATA FLOW (Typical Query)
═══════════════════════════════════════════════════════════════════════════════

  USER INPUT: "Who won the last F1 race?"
       │
       ↓
  COMMAND CHECK: Not a command, continue
       │
       ↓
  QUERY ANALYSIS (EnhancedQueryAnalyzer)
  ┌────────────────────────────────────────┐
  │ • Intent: CURRENT_INFO                 │
  │ • Complexity: SIMPLE                   │
  │ • Temporal: RECENT                     │
  │ • Domain: SPORTS                       │
  │ • Needs real-time: YES                 │
  │ • Confidence: 0.95                     │
  └────────────────────────────────────────┘
       │
       ↓
  ROUTING DECISION (LightningRouter)
  ┌────────────────────────────────────────┐
  │ • Check offline availability: ✓        │
  │ • Check online availability: ✓         │
  │ • Evaluate query needs: Real-time      │
  │ • Performance history: Online better   │
  │ • DECISION: ONLINE (Groq + Search)     │
  │ • Confidence: 0.92                     │
  │ • Fallback: OFFLINE                    │
  └────────────────────────────────────────┘
       │
       ↓
  ONLINE PROCESSING (OnlineLLM)
  ┌────────────────────────────────────────┐
  │ 1. Detect search need: YES             │
  │ 2. Optimize query: "F1 race winner     │
  │    latest 2025"                        │
  │ 3. Execute Google Search               │
  │    └─> 5 results returned              │
  │ 4. Build enhanced prompt:              │
  │    • Current datetime injection        │
  │    • Search results formatting         │
  │    • Personality context               │
  │    • Memory context                    │
  │ 5. Call Groq API (llama-3.1-8b)        │
  │ 6. Stream response with sources        │
  └────────────────────────────────────────┘
       │
       ↓
  RESPONSE: "🔍 Searching Google... Based on the
  latest search results, [Winner Name] won the
  last Formula 1 race at [Location] on [Date].
  [Additional details...] Sources: [1] [2]..."
       │
       ↓
  MEMORY UPDATE
  ┌────────────────────────────────────────┐
  │ • Store interaction with metadata      │
  │ • Sources: [search result URLs]        │
  │ • Timestamp: 1729812211.256            │
  │ • Extract no preferences (info query)  │
  └────────────────────────────────────────┘
       │
       ↓
  PERFORMANCE TRACKING
  ┌────────────────────────────────────────┐
  │ • System: online                       │
  │ • Response time: 3.2s                  │
  │ • Success: true                        │
  │ • Update avg: 2.8s                     │
  │ • Success rate: 98.5%                  │
  └────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════
                    EXTERNAL INTEGRATIONS
═══════════════════════════════════════════════════════════════════════════════

┌──────────────────────┐         ┌──────────────────────┐
│     OLLAMA           │         │     GROQ API         │
│  (Local on Pi)       │         │   (Cloud Service)    │
├──────────────────────┤         ├──────────────────────┤
│ • Port: 11434        │         │ • Model: llama-3.1-  │
│ • Models: Nemotron,  │         │   8b-instant         │
│   Qwen, Phi3, Gemma  │         │ • Endpoint: api.     │
│ • API: HTTP REST     │         │   groq.com           │
│ • Keep-alive: 30m    │         │ • Auth: Bearer token │
│ • Streaming: ✓       │         │ • Streaming: ✓       │
└──────────────────────┘         └──────────────────────┘
         ↑                                ↑
         │                                │
         │                                │
         └────────────┬───────────────────┘
                      │
                      │
              Pascal AI Assistant
                      │
                      │
         ┌────────────┴───────────────────┐
         │                                │
         ↓                                ↓
┌──────────────────────┐         ┌──────────────────────┐
│ Google Custom Search │         │  File System         │
│     API              │         │  (Persistence)       │
├──────────────────────┤         ├──────────────────────┤
│ • General search     │         │ • data/memory/       │
│ • News search        │         │   (JSON files)       │
│ • Query optimization │         │ • config/            │
│ • Source citation    │         │   personalities/     │
│ • 5 results/query    │         │ • .env (API keys)    │
└──────────────────────┘         └──────────────────────┘


═══════════════════════════════════════════════════════════════════════════════
                    ERROR HANDLING & FALLBACKS
═══════════════════════════════════════════════════════════════════════════════

  Query Received
       │
       ↓
  ┌─────────────────────┐
  │ Route Decision      │
  │ Primary: OFFLINE    │
  │ Fallback: ONLINE    │
  └─────────────────────┘
       │
       ↓
  Try Offline (Ollama)
       │
       ├─ SUCCESS → Response
       │
       ├─ TIMEOUT → Fallback to Online
       │     │
       │     ↓
       │  Try Online (Groq)
       │     │
       │     ├─ SUCCESS → Response
       │     │
       │     └─ FAILURE → Error Message
       │
       ├─ CONNECTION ERROR → Fallback to Online
       │
       └─ MODEL ERROR → Try Next Model
             │
             ├─ SUCCESS → Response
             │
             └─ ALL MODELS FAILED → Fallback to Online

Health Monitoring:
┌─────────────────────────────────────┐
│ Consecutive Errors Tracking         │
│ • 0-2 errors: Normal operation      │
│ • 3-5 errors: Reduce confidence     │
│ • 5+ errors: Mark as degraded       │
│ • Auto-recovery on success          │
└─────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════
                       PERFORMANCE OPTIMIZATION
═══════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│                    Ultra-Speed Optimizations (Pi 5)                          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  Context Window Reduction:                Response Length Limits:           │
│  ┌─────────────────────────┐             ┌─────────────────────────┐       │
│  │ • Typical: 2048 tokens  │             │ • Typical: 200 tokens   │       │
│  │ • Pascal: 128 tokens    │             │ • Pascal: 50 tokens     │       │
│  │ • Reduction: 94%        │             │ • Reduction: 75%        │       │
│  └─────────────────────────┘             └─────────────────────────┘       │
│                                                                              │
│  Connection Optimization:                 Timeout Optimization:             │
│  ┌─────────────────────────┐             ┌─────────────────────────┐       │
│  │ • Pool size: 1          │             │ • Connect: 10s → 1.5s   │       │
│  │ • Keep-alive: 30m       │             │ • Read: 30s → 4s        │       │
│  │ • DNS cache: enabled    │             │ • Total: 60s → 15s      │       │
│  └─────────────────────────┘             └─────────────────────────┘       │
│                                                                              │
│  Query Optimization:                      Model Optimization:               │
│  ┌─────────────────────────┐             ┌─────────────────────────┐       │
│  │ • Skip context for      │             │ • Keep-alive: 30m       │       │
│  │   short queries (<8w)   │             │ • Pre-loaded model      │       │
│  │ • Minimal prompts       │             │ • 4-core threading      │       │
│  │ • Compiled regex        │             │ • ARM optimization      │       │
│  └─────────────────────────┘             └─────────────────────────┘       │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

RESULT: Average response time < 2 seconds (target: 1.5s)


═══════════════════════════════════════════════════════════════════════════════
End of Architecture Diagram
═══════════════════════════════════════════════════════════════════════════════
